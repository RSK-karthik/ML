{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPZJ7Z8vLCrydPr6zFcrUqE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import files\n","data=files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"ZorJQ1rKSxX4","executionInfo":{"status":"ok","timestamp":1677479085131,"user_tz":-330,"elapsed":61310,"user":{"displayName":"Bala Chandra Shekar","userId":"02864518202078689613"}},"outputId":"931e5227-90f7-473e-e276-06aa9b65ad61"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-f25b3bfe-c345-44f8-99c5-47f82cd9d23a\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f25b3bfe-c345-44f8-99c5-47f82cd9d23a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving second.csv to second.csv\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWsRkWXnQRuV"},"outputs":[],"source":["import pandas as pd\n","import math\n","import numpy as np\n","\n","data = pd.read_csv(\"weather.nominal.csv\")\n","features = [feat for feat in data]\n","features.remove('play')"]},{"cell_type":"code","source":["class Node:\n","  def __init__(self):\n","    self.children=[]\n","    self.value=\"\"\n","    self.isLeaf=False\n","    self.pred=\"\""],"metadata":{"id":"hJsJgasyTT_O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def entropy(examples):\n","    pos = 0.0\n","    neg = 0.0\n","    for _, row in examples.iterrows():\n","        if row[\"play\"] == \"yes\":\n","            pos += 1\n","        else:\n","            neg += 1\n","    if pos == 0.0 or neg == 0.0:\n","        return 0.0\n","    else:\n","        p = pos / (pos + neg)\n","        n = neg / (pos + neg)\n","        return -(p * math.log(p, 2) + n * math.log(n, 2))"],"metadata":{"id":"RjLtfDiWTdRx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def info_gain(examples, attr):\n","    uniq = np.unique(examples[attr])\n","    #print (\"\\n\",uniq)\n","    gain = entropy(examples)\n","    #print (\"\\n\",gain)\n","    for u in uniq:\n","        subdata = examples[examples[attr] == u]\n","        #print (\"\\n\",subdata)\n","        sub_e = entropy(subdata)\n","        gain -= (float(len(subdata)) / float(len(examples))) * sub_e\n","        #print (\"\\n\",gain)\n","    return gain"],"metadata":{"id":"1rnQ6mIYTiqr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ID3(examples, attrs):\n","    root = Node()\n","\n","    max_gain = 0\n","    max_feat = \"\"\n","    for feature in attrs:\n","        #print (\"\\n\",examples)\n","        gain = info_gain(examples, feature)\n","        if gain > max_gain:\n","            max_gain = gain\n","            max_feat = feature\n","    root.value = max_feat\n","    #print (\"\\nMax feature attr\",max_feat)\n","    uniq = np.unique(examples[max_feat])\n","    #print (\"\\n\",uniq)\n","    for u in uniq:\n","        #print (\"\\n\",u)\n","        subdata = examples[examples[max_feat] == u]\n","        #print (\"\\n\",subdata)\n","        if entropy(subdata) == 0.0:\n","            newNode = Node()\n","            newNode.isLeaf = True\n","            newNode.value = u\n","            newNode.pred = np.unique(subdata[\"play\"])\n","            root.children.append(newNode)\n","        else:\n","            dummyNode = Node()\n","            dummyNode.value = u\n","            new_attrs = attrs.copy()\n","            new_attrs.remove(max_feat)\n","            child = ID3(subdata, new_attrs)\n","            dummyNode.children.append(child)\n","            root.children.append(dummyNode)\n","\n","    return root"],"metadata":{"id":"IFWAFmQTTtKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def printTree(root: Node, depth=0):\n","    for i in range(depth):\n","        print(\"\\t\", end=\"\")\n","    print(root.value, end=\"\")\n","    if root.isLeaf:\n","        print(\" -> \", root.pred)\n","    print()\n","    for child in root.children:\n","        printTree(child, depth + 1)"],"metadata":{"id":"Oes-Kv2PUpmE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def classify(root: Node, new):\n","    for child in root.children:\n","        if child.value == new[root.value]:\n","            if child.isLeaf:\n","                print (\"Predicted Label for new example\", new,\" is:\", child.pred)\n","                exit\n","            else:\n","                classify (child.children[0], new)"],"metadata":{"id":"0l_ie6ceUter"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["root = ID3(data, features)\n","print(\"Decision Tree is:\")\n","printTree(root)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fsa2GIM9Uxal","executionInfo":{"status":"ok","timestamp":1677475436505,"user_tz":-330,"elapsed":392,"user":{"displayName":"Bala Chandra Shekar","userId":"02864518202078689613"}},"outputId":"7e9f7d6e-9aad-4cc0-8d36-68081c254697"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Decision Tree is:\n","outlook\n","\tovercast ->  ['yes']\n","\n","\trainy\n","\t\twindy\n","\t\t\tFalse ->  ['yes']\n","\n","\t\t\tTrue ->  ['no']\n","\n","\tsunny\n","\t\thumidity\n","\t\t\thigh ->  ['no']\n","\n","\t\t\tnormal ->  ['yes']\n","\n","------------------\n","Predicted Label for new example {'outlook': 'sunny', 'temperature': 'hot', 'humidity': 'normal', 'wind': 'strong'}  is: ['yes']\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","train_data_m = pd.read_csv(\"second.csv\")\n","test_data_m = pd.read_csv(\"second.csv\")\n","train_data_m.head()\n","\n","def calc_total_entropy(train_data, label, class_list):\n","    total_row = train_data.shape[0]\n","    total_entr = 0\n","   \n","    for c in class_list:\n","        total_class_count = train_data[train_data[label] == c].shape[0]\n","        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row)\n","        total_entr += total_class_entr\n","   \n","    return total_entr\n","\n","def calc_entropy(feature_value_data, label, class_list):\n","    class_count = feature_value_data.shape[0]\n","    entropy = 0\n","   \n","    for c in class_list:\n","        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0]\n","   \n","        entropy_class = 0\n","        if label_class_count != 0:\n","            probability_class = label_class_count/class_count\n","            entropy_class = - probability_class * np.log2(probability_class)\n","       \n","        entropy += entropy_class\n","       \n","    return entropy\n","\n","def calc_info_gain(feature_name, train_data, label, class_list):\n","    feature_value_list = train_data[feature_name].unique()\n","    total_row = train_data.shape[0]\n","    feature_info = 0.0\n","   \n","    for feature_value in feature_value_list:\n","        feature_value_data = train_data[train_data[feature_name] == feature_value]\n","        feature_value_count = feature_value_data.shape[0]\n","        feature_value_entropy = calc_entropy(feature_value_data, label, class_list)\n","        feature_value_probability = feature_value_count/total_row\n","        feature_info += feature_value_probability * feature_value_entropy\n","       \n","    return calc_total_entropy(train_data, label, class_list) - feature_info\n","\n","def find_most_informative_feature(train_data, label, class_list):\n","    feature_list = train_data.columns.drop(label)\n","    max_info_gain = -1\n","    max_info_feature = None\n","   \n","    for feature in feature_list:  \n","        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n","        if max_info_gain < feature_info_gain:\n","            max_info_gain = feature_info_gain\n","            max_info_feature = feature\n","           \n","    return max_info_feature\n","\n","def generate_sub_tree(feature_name, train_data, label, class_list):\n","    feature_value_count_dict = train_data[feature_name].value_counts(sort=False)\n","    tree = {}\n","   \n","    for feature_value, count in feature_value_count_dict.items():\n","        feature_value_data = train_data[train_data[feature_name] == feature_value]\n","       \n","        assigned_to_node = False\n","        for c in class_list:\n","            class_count = feature_value_data[feature_value_data[label] == c].shape[0]\n","\n","            if class_count == count:\n","                tree[feature_value] = c\n","                train_data = train_data[train_data[feature_name] != feature_value]\n","                assigned_to_node = True\n","        if not assigned_to_node:\n","            tree[feature_value] = \"?\"\n","           \n","    return tree, train_data\n","\n","def make_tree(root, prev_feature_value, train_data, label, class_list):\n","    if train_data.shape[0] != 0:\n","        max_info_feature = find_most_informative_feature(train_data, label, class_list)\n","        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list)\n","        next_root = None\n","       \n","        if prev_feature_value != None:\n","            root[prev_feature_value] = dict()\n","            root[prev_feature_value][max_info_feature] = tree\n","            next_root = root[prev_feature_value][max_info_feature]\n","        else:\n","            root[max_info_feature] = tree\n","            next_root = root[max_info_feature]\n","       \n","        for node, branch in list(next_root.items()):\n","            if branch == \"?\":\n","                feature_value_data = train_data[train_data[max_info_feature] == node]\n","                make_tree(next_root, node, feature_value_data, label, class_list)\n","\n","def id3(train_data_m, label):\n","    train_data = train_data_m.copy()\n","    tree = {}\n","    class_list = train_data[label].unique()\n","    make_tree(tree, None, train_data, label, class_list)\n","   \n","    return tree\n","\n","def predict(tree, instance):\n","    if not isinstance(tree, dict):\n","        return tree\n","    else:\n","        root_node = next(iter(tree))\n","        feature_value = instance[root_node]\n","        if feature_value in tree[root_node]:\n","            return predict(tree[root_node][feature_value], instance)\n","        else:\n","            return None\n","       \n","def evaluate(tree, test_data_m, label):\n","    correct_predict = 0\n","    wrong_predict = 0\n","    for index, row in test_data_m.iterrows():\n","        result = predict(tree, test_data_m.iloc[index])\n","        if result == test_data_m[label].iloc[index]:\n","            correct_predict += 1\n","        else:\n","            wrong_predict += 1\n","   \n","tree = id3(train_data_m,'Buys')\n","print(tree)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xU9mz2y9jIAg","executionInfo":{"status":"ok","timestamp":1677479165536,"user_tz":-330,"elapsed":6,"user":{"displayName":"Bala Chandra Shekar","userId":"02864518202078689613"}},"outputId":"b2e77df4-98bf-4323-d00c-43c61f1f3fea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Age': {'Youth': {'Student': {'No': 'No', 'Yes': 'Yes'}}, 'Middle aged': 'Yes', 'Senior': {'Credit_rating': {'Fair': 'Yes', 'Excellent': 'No'}}}}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"AwP-BbUZigoU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.stats import zscore\n","import math\n","import pandas as pd\n","df = pd.read_csv(\"employees.csv\")\n","column = df[\"SALARY\"]\n","meanSalary = df[\"SALARY\"].mean()\n","df.fillna(meanSalary, inplace=True)\n","# min-max normalization\n","new_min, new_max = [int(x) for x in input(\"Enter the new min and new max value for minmax nomralization: \").split()]\n","min_max_normalized_values = ((column - column.min()) / (column.max() - column.min())) * (new_max - new_min) + new_min\n","# Z-score normalization\n","z_score_normalized_values = zscore(list(df[\"SALARY\"]))\n","# decimal normalization\n","n = math.ceil(math.log(column.max(), 10))\n","decimal_normalized_values = column / 10**n\n","print(\"\\nMin-Max Normalized Values:\\n\", min_max_normalized_values)\n","print(\"\\nZ-Score Normalized Values:\\n\", z_score_normalized_values)\n","print(\"\\nDecimal Normalized Values:\\n\", decimal_normalized_values)\n","# print(column.min(), column.max())\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"-5fFpduAEz-7","executionInfo":{"status":"error","timestamp":1679853604312,"user_tz":-330,"elapsed":1753,"user":{"displayName":"Bala Chandra Shekar","userId":"02864518202078689613"}},"outputId":"8560b258-fe81-41f1-cc6f-de12799fc783"},"execution_count":1,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-be2f53b28b54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"employees.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SALARY\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmeanSalary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SALARY\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'employees.csv'"]}]}]}